hidden_dim,num_layers,batch_size,status,model_parameters,trainable_parameters,model_size_mb,gpu_allocated_baseline,gpu_allocated_after_creation,gpu_allocated_after_device,gpu_allocated_after_input,gpu_allocated_after_forward,memory_delta_model_creation,memory_delta_to_device,memory_delta_input,memory_delta_forward,gpu_memory_used_torch,gpu_peak_memory_torch,gpu_reserved_torch,gpu_memory_used_system,gpu_total_system,gpu_util_percent,system_memory_baseline,system_memory_after_device,system_memory_after_forward,cpu_memory,output_shape,error_message
64,2,32,success,53508,53508.0,0.2041168212890625,0.0234375,0.0234375,0.22998046875,48.23046875,136.68701171875,0.0,0.20654296875,48.00048828125,88.45654296875,88.45654296875,2727.23974609375,4834.0,4808.0,81920.0,6.539306640625001,501.0,501.0,5357.0,1241.375,"torch.Size([32, 3, 256, 256])",
64,2,64,success,53508,53508.0,0.2041168212890625,16.2734375,16.2734375,16.47998046875,112.48046875,256.68701171875,0.0,0.20654296875,96.00048828125,144.20654296875,144.20654296875,5447.39599609375,9674.0,9552.0,81920.0,12.447509765625,549.0,549.0,10197.0,1242.7265625,"torch.Size([64, 3, 256, 256])",
64,2,128,success,53508,53508.0,0.2041168212890625,16.2734375,16.2734375,16.47998046875,208.48095703125,496.6875,0.0,0.20654296875,192.0009765625,288.20654296875,288.20654296875,10871.458984375,19306.0,19088.0,81920.0,24.205322265625,549.0,549.0,19829.0,1255.05078125,"torch.Size([128, 3, 256, 256])",
64,2,256,success,53508,53508.0,0.2041168212890625,16.2734375,16.2734375,16.47998046875,400.48193359375,976.6884765625,0.0,0.20654296875,384.001953125,576.20654296875,576.20654296875,21719.5849609375,38570.0,38160.0,81920.0,47.720947265625,549.0,549.0,39093.0,1257.44140625,"torch.Size([256, 3, 256, 256])",
64,2,512,success,53508,53508.0,0.2041168212890625,16.2734375,16.2734375,16.47998046875,784.48388671875,1936.6904296875,0.0,0.20654296875,768.00390625,1152.20654296875,1152.20654296875,43415.8369140625,77098.0,76304.0,81920.0,94.752197265625,549.0,549.0,77621.0,1258.05078125,"torch.Size([512, 3, 256, 256])",
64,4,32,success,127364,127364.0,0.4858551025390625,16.2734375,16.2734375,16.76220703125,64.7626953125,137.25146484375,0.0,0.48876953125,48.00048828125,72.48876953125,72.48876953125,3759.64697265625,5886.0,5812.0,81920.0,7.823486328125,549.0,549.0,6409.0,1282.203125,"torch.Size([32, 3, 256, 256])",
64,4,64,success,127364,127364.0,0.4858551025390625,16.2734375,16.2734375,16.76220703125,112.7626953125,257.25146484375,0.0,0.48876953125,96.00048828125,144.48876953125,144.48876953125,7495.67822265625,11726.0,11604.0,81920.0,14.952392578125002,549.0,549.0,12249.0,1282.22265625,"torch.Size([64, 3, 256, 256])",
64,4,128,success,127364,127364.0,0.4858551025390625,16.2734375,16.2734375,16.76220703125,208.76318359375,497.251953125,0.0,0.48876953125,192.0009765625,288.48876953125,288.48876953125,14967.7412109375,23406.0,23188.0,81920.0,29.210205078125,549.0,549.0,23929.0,1282.32421875,"torch.Size([128, 3, 256, 256])",
64,4,256,success,127364,127364.0,0.4858551025390625,16.2734375,16.2734375,16.76220703125,400.76416015625,977.2529296875,0.0,0.48876953125,384.001953125,576.48876953125,576.48876953125,29911.8671875,46766.0,46356.0,81920.0,57.72583007812499,549.0,549.0,47289.0,1282.328125,"torch.Size([256, 3, 256, 256])",
64,4,512,success,127364,127364.0,0.4858551025390625,16.2734375,16.2734375,16.76220703125,784.76611328125,1937.2548828125,0.0,0.48876953125,768.00390625,1152.48876953125,1152.48876953125,59800.119140625,59816.0,59022.0,81920.0,73.656005859375,549.0,549.0,60339.0,1282.328125,"torch.Size([512, 3, 256, 256])",
64,6,32,success,201220,201220.0,0.7675933837890625,16.2734375,16.2734375,17.04443359375,65.044921875,137.81591796875,0.0,0.77099609375,48.00048828125,72.77099609375,72.77099609375,4783.92919921875,6914.0,6840.0,81920.0,9.078369140625,549.0,549.0,7437.0,1282.62109375,"torch.Size([32, 3, 256, 256])",
64,6,64,success,201220,201220.0,0.7675933837890625,16.2734375,16.2734375,17.04443359375,113.044921875,257.81591796875,0.0,0.77099609375,96.00048828125,144.77099609375,144.77099609375,9543.96044921875,13778.0,13656.0,81920.0,17.457275390625,549.0,549.0,14301.0,1282.62109375,"torch.Size([64, 3, 256, 256])",
64,6,128,success,201220,201220.0,0.7675933837890625,16.2734375,16.2734375,17.04443359375,209.04541015625,497.81640625,0.0,0.77099609375,192.0009765625,288.77099609375,288.77099609375,19064.0234375,27506.0,27288.0,81920.0,34.215087890625,549.0,549.0,28029.0,1282.62109375,"torch.Size([128, 3, 256, 256])",
64,6,256,success,201220,201220.0,0.7675933837890625,16.2734375,16.2734375,17.04443359375,401.04638671875,977.8173828125,0.0,0.77099609375,384.001953125,576.77099609375,576.77099609375,38104.1494140625,54964.0,54554.0,81920.0,67.733154296875,549.0,549.0,55487.0,1282.62109375,"torch.Size([256, 3, 256, 256])",
64,6,512,success,201220,201220.0,0.7675933837890625,16.2734375,16.2734375,17.04443359375,785.04833984375,1937.8193359375,0.0,0.77099609375,768.00390625,1152.77099609375,1152.77099609375,76184.4013671875,76206.0,75412.0,81920.0,93.663330078125,549.0,549.0,76729.0,1282.62109375,"torch.Size([512, 3, 256, 256])",
64,8,32,success,275076,275076.0,1.0493316650390625,16.2734375,16.2734375,17.32666015625,65.3271484375,138.38037109375,0.0,1.05322265625,48.00048828125,73.05322265625,73.05322265625,5808.21142578125,7944.0,7870.0,81920.0,10.335693359375,549.0,549.0,8467.0,1282.90234375,"torch.Size([32, 3, 256, 256])",
64,8,64,success,275076,275076.0,1.0493316650390625,16.2734375,16.2734375,17.32666015625,113.3271484375,258.38037109375,0.0,1.05322265625,96.00048828125,145.05322265625,145.05322265625,11592.24267578125,15832.0,15710.0,81920.0,19.964599609375,549.0,549.0,16355.0,1282.9140625,"torch.Size([64, 3, 256, 256])",
64,8,128,success,275076,275076.0,1.0493316650390625,16.2734375,16.2734375,17.32666015625,209.32763671875,498.380859375,0.0,1.05322265625,192.0009765625,289.05322265625,289.05322265625,23160.3056640625,31608.0,31390.0,81920.0,39.222412109375,549.0,549.0,32131.0,1282.92578125,"torch.Size([128, 3, 256, 256])",
64,8,256,success,275076,275076.0,1.0493316650390625,16.2734375,16.2734375,17.32666015625,401.32861328125,978.3818359375,0.0,1.05322265625,384.001953125,577.05322265625,577.05322265625,46296.431640625,63160.0,62750.0,81920.0,77.738037109375,549.0,549.0,63683.0,1282.92578125,"torch.Size([256, 3, 256, 256])",
64,8,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 4.22 GiB is free. Including non-PyTorch memory, this process has 74.92 GiB memory in use. Of the allocated memory 66.77 GiB is allocated by PyTorch, and 7.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
64,10,32,success,348932,348932.0,1.3310699462890625,16.2734375,16.2734375,17.60888671875,65.609375,138.94482421875,0.0,1.33544921875,48.00048828125,73.33544921875,73.33544921875,6832.49365234375,8972.0,8898.0,81920.0,11.590576171875,549.0,549.0,9495.0,1287.5234375,"torch.Size([32, 3, 256, 256])",
64,10,64,success,348932,348932.0,1.3310699462890625,16.2734375,16.2734375,17.60888671875,113.609375,258.94482421875,0.0,1.33544921875,96.00048828125,145.33544921875,145.33544921875,13640.52490234375,17884.0,17762.0,81920.0,22.469482421875,549.0,549.0,18407.0,1287.5390625,"torch.Size([64, 3, 256, 256])",
64,10,128,success,348932,348932.0,1.3310699462890625,16.2734375,16.2734375,17.60888671875,209.60986328125,498.9453125,0.0,1.33544921875,192.0009765625,289.33544921875,289.33544921875,27256.587890625,35708.0,35490.0,81920.0,44.227294921875,549.0,549.0,36231.0,1287.5625,"torch.Size([128, 3, 256, 256])",
64,10,256,success,348932,348932.0,1.3310699462890625,16.2734375,16.2734375,17.60888671875,401.61083984375,978.9462890625,0.0,1.33544921875,384.001953125,577.33544921875,577.33544921875,54488.7138671875,71356.0,70946.0,81920.0,87.742919921875,549.0,549.0,71879.0,1287.578125,"torch.Size([256, 3, 256, 256])",
64,10,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 4.98 GiB is free. Including non-PyTorch memory, this process has 74.17 GiB memory in use. Of the allocated memory 73.64 GiB is allocated by PyTorch, and 21.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
64,12,32,success,422788,422788.0,1.6128082275390625,16.2734375,16.2734375,17.89111328125,65.8916015625,139.50927734375,0.0,1.61767578125,48.00048828125,73.61767578125,73.61767578125,7856.77587890625,10000.0,9926.0,81920.0,12.845458984375,549.0,549.0,10523.0,1290.29296875,"torch.Size([32, 3, 256, 256])",
64,12,64,success,422788,422788.0,1.6128082275390625,16.2734375,16.2734375,17.89111328125,113.8916015625,259.50927734375,0.0,1.61767578125,96.00048828125,145.61767578125,145.61767578125,15688.80712890625,19936.0,19814.0,81920.0,24.974365234375,549.0,549.0,20459.0,1290.29296875,"torch.Size([64, 3, 256, 256])",
64,12,128,success,422788,422788.0,1.6128082275390625,16.2734375,16.2734375,17.89111328125,209.89208984375,499.509765625,0.0,1.61767578125,192.0009765625,289.61767578125,289.61767578125,31352.8701171875,39808.0,39590.0,81920.0,49.232177734375,549.0,549.0,40331.0,1290.29296875,"torch.Size([128, 3, 256, 256])",
64,12,256,success,422788,422788.0,1.6128082275390625,16.2734375,16.2734375,17.89111328125,401.89306640625,979.5107421875,0.0,1.61767578125,384.001953125,577.61767578125,577.61767578125,62680.99609375,79552.0,79142.0,81920.0,97.747802734375,549.0,549.0,80075.0,1290.29296875,"torch.Size([256, 3, 256, 256])",
64,12,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 4.99 GiB is free. Including non-PyTorch memory, this process has 74.15 GiB memory in use. Of the allocated memory 73.64 GiB is allocated by PyTorch, and 9.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
64,20,32,success,718212,718212.0,2.7397613525390625,16.2734375,16.2734375,19.02001953125,67.0205078125,141.76708984375,0.0,2.74658203125,48.00048828125,74.74658203125,74.74658203125,11953.90478515625,14114.0,14038.0,81920.0,17.867431640625,549.0,551.0,14637.0,1291.421875,"torch.Size([32, 3, 256, 256])",
64,20,64,success,718212,718212.0,2.7397613525390625,16.2734375,16.2734375,19.02001953125,115.0205078125,261.76708984375,0.0,2.74658203125,96.00048828125,146.74658203125,146.74658203125,23881.93603515625,28146.0,28022.0,81920.0,34.996337890625,549.0,551.0,28669.0,1291.44140625,"torch.Size([64, 3, 256, 256])",
64,20,128,success,718212,718212.0,2.7397613525390625,16.2734375,16.2734375,19.02001953125,211.02099609375,501.767578125,0.0,2.74658203125,192.0009765625,290.74658203125,290.74658203125,47737.9990234375,56210.0,55990.0,81920.0,69.254150390625,549.0,551.0,56733.0,1291.4453125,"torch.Size([128, 3, 256, 256])",
64,20,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 1.77 GiB is free. Including non-PyTorch memory, this process has 77.38 GiB memory in use. Of the allocated memory 76.83 GiB is allocated by PyTorch, and 42.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
64,20,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 4.99 GiB is free. Including non-PyTorch memory, this process has 74.15 GiB memory in use. Of the allocated memory 73.64 GiB is allocated by PyTorch, and 8.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,2,32,success,188932,188932.0,0.7207183837890625,16.2734375,16.2734375,16.9951171875,64.99560546875,137.71728515625,0.0,0.7216796875,48.00048828125,72.7216796875,72.7216796875,5296.3701171875,9474.0,9400.0,81920.0,12.203369140625,549.0,549.0,9997.0,1293.91015625,"torch.Size([32, 3, 256, 256])",
128,2,64,success,188932,188932.0,0.7207183837890625,16.2734375,16.2734375,16.9951171875,112.99560546875,257.71728515625,0.0,0.7216796875,96.00048828125,144.7216796875,144.7216796875,10568.4169921875,18906.0,18784.0,81920.0,23.717041015625,549.0,549.0,19429.0,1294.14453125,"torch.Size([64, 3, 256, 256])",
128,2,128,success,188932,188932.0,0.7207183837890625,16.2734375,16.2734375,16.9951171875,208.99609375,497.7177734375,0.0,0.7216796875,192.0009765625,288.7216796875,288.7216796875,21112.51123046875,37770.0,37552.0,81920.0,46.744384765625,549.0,549.0,38293.0,1294.40234375,"torch.Size([128, 3, 256, 256])",
128,2,256,success,188932,188932.0,0.7207183837890625,16.2734375,16.2734375,16.9951171875,400.9970703125,977.71875,0.0,0.7216796875,384.001953125,576.7216796875,576.7216796875,42200.69970703125,75500.0,75090.0,81920.0,92.801513671875,549.0,549.0,76023.0,1294.4609375,"torch.Size([256, 3, 256, 256])",
128,2,512,success,188932,188932.0,0.7207183837890625,16.2734375,16.2734375,16.9951171875,784.9990234375,1937.720703125,0.0,0.7216796875,768.00390625,1152.7216796875,1152.7216796875,67993.07666015625,68004.0,67210.0,81920.0,83.651123046875,549.0,549.0,68527.0,1294.8671875,"torch.Size([512, 3, 256, 256])",
128,4,32,success,484100,484100.0,1.8466949462890625,16.2734375,16.2734375,18.12109375,66.12158203125,139.96923828125,0.0,1.84765625,48.00048828125,73.84765625,73.84765625,7345.49609375,11528.0,11454.0,81920.0,14.710693359374998,549.0,549.0,12051.0,1297.03515625,"torch.Size([32, 3, 256, 256])",
128,4,64,success,484100,484100.0,1.8466949462890625,16.2734375,16.2734375,18.12109375,114.12158203125,259.96923828125,0.0,1.84765625,96.00048828125,145.84765625,145.84765625,14665.54296875,23008.0,22886.0,81920.0,28.724365234375,549.0,549.0,23531.0,1297.0390625,"torch.Size([64, 3, 256, 256])",
128,4,128,success,484100,484100.0,1.8466949462890625,16.2734375,16.2734375,18.12109375,210.1220703125,499.9697265625,0.0,1.84765625,192.0009765625,289.84765625,289.84765625,29305.63720703125,45970.0,45752.0,81920.0,56.754150390625,549.0,549.0,46493.0,1297.0390625,"torch.Size([128, 3, 256, 256])",
128,4,256,success,484100,484100.0,1.8466949462890625,16.2734375,16.2734375,18.12109375,402.123046875,979.970703125,0.0,1.84765625,384.001953125,577.84765625,577.84765625,58585.82568359375,58604.0,58194.0,81920.0,72.176513671875,549.0,549.0,59127.0,1297.0390625,"torch.Size([256, 3, 256, 256])",
128,4,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.99 GiB is free. Including non-PyTorch memory, this process has 66.15 GiB memory in use. Of the allocated memory 65.64 GiB is allocated by PyTorch, and 9.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,6,32,success,779268,779268.0,2.9726715087890625,16.2734375,16.2734375,19.2470703125,67.24755859375,142.22119140625,0.0,2.9736328125,48.00048828125,74.9736328125,74.9736328125,9394.6220703125,13584.0,13508.0,81920.0,17.220458984375,549.0,551.0,14107.0,1297.60546875,"torch.Size([32, 3, 256, 256])",
128,6,64,success,779268,779268.0,2.9726715087890625,16.2734375,16.2734375,19.2470703125,115.24755859375,262.22119140625,0.0,2.9736328125,96.00048828125,146.9736328125,146.9736328125,18762.6689453125,27112.0,26988.0,81920.0,33.734130859375,549.0,551.0,27635.0,1297.60546875,"torch.Size([64, 3, 256, 256])",
128,6,128,success,779268,779268.0,2.9726715087890625,16.2734375,16.2734375,19.2470703125,211.248046875,502.2216796875,0.0,2.9736328125,192.0009765625,290.9736328125,290.9736328125,37498.76318359375,54168.0,53948.0,81920.0,66.761474609375,549.0,551.0,54691.0,1297.60546875,"torch.Size([128, 3, 256, 256])",
128,6,256,success,779268,779268.0,2.9726715087890625,16.2734375,16.2734375,19.2470703125,403.2490234375,982.22265625,0.0,2.9736328125,384.001953125,578.9736328125,578.9736328125,74970.95166015625,74994.0,74582.0,81920.0,92.183837890625,549.0,551.0,75517.0,1297.60546875,"torch.Size([256, 3, 256, 256])",
128,6,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.99 GiB is free. Including non-PyTorch memory, this process has 66.16 GiB memory in use. Of the allocated memory 65.64 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,8,32,success,1074436,1074436.0,4.0986480712890625,16.2734375,16.2734375,20.373046875,68.37353515625,144.47314453125,0.0,4.099609375,48.00048828125,76.099609375,76.099609375,11443.748046875,15638.0,15560.0,81920.0,19.727783203125,549.0,553.0,16161.0,1298.734375,"torch.Size([32, 3, 256, 256])",
128,8,64,success,1074436,1074436.0,4.0986480712890625,16.2734375,16.2734375,20.373046875,116.37353515625,264.47314453125,0.0,4.099609375,96.00048828125,148.099609375,148.099609375,22859.794921875,31214.0,31088.0,81920.0,38.741455078125,549.0,553.0,31737.0,1298.734375,"torch.Size([64, 3, 256, 256])",
128,8,128,success,1074436,1074436.0,4.0986480712890625,16.2734375,16.2734375,20.373046875,212.3740234375,504.4736328125,0.0,4.099609375,192.0009765625,292.099609375,292.099609375,45691.88916015625,62366.0,62144.0,81920.0,76.768798828125,549.0,553.0,62889.0,1298.734375,"torch.Size([128, 3, 256, 256])",
128,8,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 5.35 GiB is free. Including non-PyTorch memory, this process has 73.80 GiB memory in use. Of the allocated memory 65.40 GiB is allocated by PyTorch, and 7.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,8,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.99 GiB is free. Including non-PyTorch memory, this process has 66.16 GiB memory in use. Of the allocated memory 65.65 GiB is allocated by PyTorch, and 8.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,10,32,success,1369604,1369604.0,5.2246246337890625,16.2734375,16.2734375,21.4990234375,69.49951171875,146.72509765625,0.0,5.2255859375,48.00048828125,77.2255859375,77.2255859375,13492.8740234375,17692.0,17614.0,81920.0,22.235107421875,549.0,553.0,18215.0,1299.86328125,"torch.Size([32, 3, 256, 256])",
128,10,64,success,1369604,1369604.0,5.2246246337890625,16.2734375,16.2734375,21.4990234375,117.49951171875,266.72509765625,0.0,5.2255859375,96.00048828125,149.2255859375,149.2255859375,26956.9208984375,35316.0,35190.0,81920.0,43.748779296875,549.0,553.0,35839.0,1299.8671875,"torch.Size([64, 3, 256, 256])",
128,10,128,success,1369604,1369604.0,5.2246246337890625,16.2734375,16.2734375,21.4990234375,213.5,506.7255859375,0.0,5.2255859375,192.0009765625,293.2255859375,293.2255859375,53885.01513671875,70564.0,70342.0,81920.0,86.776123046875,549.0,553.0,71087.0,1299.8671875,"torch.Size([128, 3, 256, 256])",
128,10,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 5.78 GiB is free. Including non-PyTorch memory, this process has 73.36 GiB memory in use. Of the allocated memory 72.83 GiB is allocated by PyTorch, and 22.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,10,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.98 GiB is free. Including non-PyTorch memory, this process has 66.16 GiB memory in use. Of the allocated memory 65.65 GiB is allocated by PyTorch, and 9.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,12,32,success,1664772,1664772.0,6.3506011962890625,16.2734375,16.2734375,22.625,70.62548828125,148.97705078125,0.0,6.3515625,48.00048828125,78.3515625,78.3515625,15542.0,19748.0,19668.0,81920.0,24.744873046875,549.0,555.0,20271.0,1300.9921875,"torch.Size([32, 3, 256, 256])",
128,12,64,success,1664772,1664772.0,6.3506011962890625,16.2734375,16.2734375,22.625,118.62548828125,268.97705078125,0.0,6.3515625,96.00048828125,150.3515625,150.3515625,31054.046875,39420.0,39292.0,81920.0,48.758544921875,549.0,555.0,39943.0,1300.9921875,"torch.Size([64, 3, 256, 256])",
128,12,128,success,1664772,1664772.0,6.3506011962890625,16.2734375,16.2734375,22.625,214.6259765625,508.9775390625,0.0,6.3515625,192.0009765625,294.3515625,294.3515625,62078.14111328125,78764.0,78540.0,81920.0,96.785888671875,549.0,555.0,79287.0,1300.9921875,"torch.Size([128, 3, 256, 256])",
128,12,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 5.80 GiB is free. Including non-PyTorch memory, this process has 73.35 GiB memory in use. Of the allocated memory 72.83 GiB is allocated by PyTorch, and 9.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,12,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.98 GiB is free. Including non-PyTorch memory, this process has 66.16 GiB memory in use. Of the allocated memory 65.65 GiB is allocated by PyTorch, and 8.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,20,32,success,2845444,2845444.0,10.854507446289062,16.2734375,16.2734375,27.12890625,75.12939453125,157.98486328125,0.0,10.85546875,48.00048828125,82.85546875,82.85546875,23738.50390625,27966.0,27880.0,81920.0,34.776611328125,549.0,561.0,28489.0,1305.49609375,"torch.Size([32, 3, 256, 256])",
128,20,64,success,2845444,2845444.0,10.854507446289062,16.2734375,16.2734375,27.12890625,123.12939453125,277.98486328125,0.0,10.85546875,96.00048828125,154.85546875,154.85546875,47442.55078125,55830.0,55696.0,81920.0,68.790283203125,549.0,561.0,56353.0,1305.51171875,"torch.Size([64, 3, 256, 256])",
128,20,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 2.16 GiB is free. Including non-PyTorch memory, this process has 76.98 GiB memory in use. Of the allocated memory 76.43 GiB is allocated by PyTorch, and 44.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,20,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 5.79 GiB is free. Including non-PyTorch memory, this process has 73.35 GiB memory in use. Of the allocated memory 72.84 GiB is allocated by PyTorch, and 10.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
128,20,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.98 GiB is free. Including non-PyTorch memory, this process has 66.16 GiB memory in use. Of the allocated memory 65.65 GiB is allocated by PyTorch, and 10.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,2,32,success,705540,705540.0,2.6914215087890625,16.2734375,16.2734375,18.9658203125,66.96630859375,141.65869140625,0.0,2.6923828125,48.00048828125,74.6923828125,74.6923828125,10415.572265625,12542.0,12468.0,81920.0,15.948486328125,549.0,549.0,13065.0,1307.00390625,"torch.Size([32, 3, 256, 256])",
256,2,64,success,705540,705540.0,2.6914215087890625,16.2734375,16.2734375,18.9658203125,114.96630859375,261.65869140625,0.0,2.6923828125,96.00048828125,146.6923828125,146.6923828125,20807.650390625,25046.0,24924.0,81920.0,31.212158203125,549.0,549.0,25569.0,1307.17578125,"torch.Size([64, 3, 256, 256])",
256,2,128,success,705540,705540.0,2.6914215087890625,16.2734375,16.2734375,18.9658203125,210.966796875,501.6591796875,0.0,2.6923828125,192.0009765625,290.6923828125,290.6923828125,41591.80712890625,50054.0,49836.0,81920.0,61.739501953125,549.0,549.0,50577.0,1307.17578125,"torch.Size([128, 3, 256, 256])",
256,2,256,success,705540,705540.0,2.6914215087890625,16.2734375,16.2734375,18.9658203125,402.9677734375,981.66015625,0.0,2.6923828125,384.001953125,578.6923828125,578.6923828125,66776.12060546875,66784.0,66374.0,81920.0,82.161865234375,549.0,549.0,67307.0,1307.53125,"torch.Size([256, 3, 256, 256])",
256,2,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.99 GiB is free. Including non-PyTorch memory, this process has 66.15 GiB memory in use. Of the allocated memory 65.64 GiB is allocated by PyTorch, and 7.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,4,32,success,1885700,1885700.0,7.1933746337890625,16.2734375,16.2734375,24.4677734375,72.46826171875,151.66259765625,0.0,8.1943359375,48.00048828125,79.1943359375,79.1943359375,14517.07421875,16646.0,16572.0,81920.0,20.958251953125,549.0,549.0,17169.0,1307.53125,"torch.Size([32, 3, 256, 256])",
256,4,64,success,1885700,1885700.0,7.1933746337890625,16.2734375,16.2734375,24.4677734375,120.46826171875,271.66259765625,0.0,8.1943359375,96.00048828125,151.1943359375,151.1943359375,29005.15234375,33246.0,33124.0,81920.0,41.221923828125,549.0,549.0,33769.0,1307.53125,"torch.Size([64, 3, 256, 256])",
256,4,128,success,1885700,1885700.0,7.1933746337890625,16.2734375,16.2734375,24.4677734375,216.46875,511.6630859375,0.0,8.1943359375,192.0009765625,295.1943359375,295.1943359375,57981.30908203125,66446.0,66228.0,81920.0,81.749267578125,549.0,549.0,66969.0,1307.53125,"torch.Size([128, 3, 256, 256])",
256,4,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.80 GiB is free. Including non-PyTorch memory, this process has 65.34 GiB memory in use. Of the allocated memory 64.84 GiB is allocated by PyTorch, and 926.00 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,4,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.99 GiB is free. Including non-PyTorch memory, this process has 66.15 GiB memory in use. Of the allocated memory 65.65 GiB is allocated by PyTorch, and 2.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,6,32,success,3065860,3065860.0,11.695327758789062,16.2734375,16.2734375,28.9697265625,76.97021484375,160.66650390625,0.0,12.6962890625,48.00048828125,83.6962890625,83.6962890625,18617.576171875,20770.0,20676.0,81920.0,25.992431640625004,549.0,569.0,21293.0,1307.53125,"torch.Size([32, 3, 256, 256])",
256,6,64,success,3065860,3065860.0,11.695327758789062,16.2734375,16.2734375,28.9697265625,124.97021484375,280.66650390625,0.0,12.6962890625,96.00048828125,155.6962890625,155.6962890625,37201.654296875,41466.0,41324.0,81920.0,51.25610351562499,549.0,569.0,41989.0,1307.53515625,"torch.Size([64, 3, 256, 256])",
256,6,128,success,3065860,3065860.0,11.695327758789062,16.2734375,16.2734375,28.9697265625,220.970703125,520.6669921875,0.0,12.6962890625,192.0009765625,299.6962890625,299.6962890625,74369.81103515625,74532.0,74294.0,81920.0,91.619873046875,549.0,569.0,75055.0,1307.53515625,"torch.Size([128, 3, 256, 256])",
256,6,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.78 GiB is free. Including non-PyTorch memory, this process has 65.36 GiB memory in use. Of the allocated memory 64.84 GiB is allocated by PyTorch, and 16.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,6,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 66.17 GiB memory in use. Of the allocated memory 65.65 GiB is allocated by PyTorch, and 17.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,8,32,success,4246020,4246020.0,16.197280883789062,16.2734375,16.2734375,33.4716796875,81.47216796875,169.67041015625,0.0,17.1982421875,48.00048828125,88.1982421875,88.1982421875,22718.078125,24874.0,24780.0,81920.0,31.002197265624996,549.0,569.0,25397.0,1319.01171875,"torch.Size([32, 3, 256, 256])",
256,8,64,success,4246020,4246020.0,16.197280883789062,16.2734375,16.2734375,33.4716796875,129.47216796875,289.67041015625,0.0,17.1982421875,96.00048828125,160.1982421875,160.1982421875,45398.15625,49666.0,49524.0,81920.0,61.26586914062499,549.0,569.0,50189.0,1319.01171875,"torch.Size([64, 3, 256, 256])",
256,8,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 5.94 GiB is free. Including non-PyTorch memory, this process has 73.20 GiB memory in use. Of the allocated memory 64.72 GiB is allocated by PyTorch, and 7.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,8,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.78 GiB is free. Including non-PyTorch memory, this process has 65.36 GiB memory in use. Of the allocated memory 64.85 GiB is allocated by PyTorch, and 11.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,8,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 66.17 GiB memory in use. Of the allocated memory 65.66 GiB is allocated by PyTorch, and 13.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,10,32,success,5426180,5426180.0,20.699234008789062,16.2734375,16.2734375,37.9736328125,85.97412109375,178.67431640625,0.0,21.7001953125,48.00048828125,92.7001953125,92.7001953125,26818.580078125,28978.0,28884.0,81920.0,36.011962890625,549.0,569.0,29501.0,1323.265625,"torch.Size([32, 3, 256, 256])",
256,10,64,success,5426180,5426180.0,20.699234008789062,16.2734375,16.2734375,37.9736328125,133.97412109375,298.67431640625,0.0,21.7001953125,96.00048828125,164.7001953125,164.7001953125,53594.658203125,57866.0,57724.0,81920.0,71.275634765625,549.0,569.0,58389.0,1323.51171875,"torch.Size([64, 3, 256, 256])",
256,10,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 6.16 GiB is free. Including non-PyTorch memory, this process has 72.98 GiB memory in use. Of the allocated memory 72.44 GiB is allocated by PyTorch, and 35.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,10,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.78 GiB is free. Including non-PyTorch memory, this process has 65.36 GiB memory in use. Of the allocated memory 64.85 GiB is allocated by PyTorch, and 7.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,10,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 66.17 GiB memory in use. Of the allocated memory 65.66 GiB is allocated by PyTorch, and 8.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,12,32,success,6606340,6606340.0,25.201187133789062,16.2734375,16.2734375,42.4755859375,90.47607421875,187.67822265625,0.0,26.2021484375,48.00048828125,97.2021484375,97.2021484375,30919.08203125,33082.0,32988.0,81920.0,41.021728515625,549.0,569.0,33605.0,1323.51171875,"torch.Size([32, 3, 256, 256])",
256,12,64,success,6606340,6606340.0,25.201187133789062,16.2734375,16.2734375,42.4755859375,138.47607421875,307.67822265625,0.0,26.2021484375,96.00048828125,169.2021484375,169.2021484375,61791.16015625,66066.0,65924.0,81920.0,81.285400390625,549.0,569.0,66589.0,1323.51171875,"torch.Size([64, 3, 256, 256])",
256,12,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 6.19 GiB is free. Including non-PyTorch memory, this process has 72.95 GiB memory in use. Of the allocated memory 72.45 GiB is allocated by PyTorch, and 3.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,12,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.78 GiB is free. Including non-PyTorch memory, this process has 65.36 GiB memory in use. Of the allocated memory 64.85 GiB is allocated by PyTorch, and 2.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,12,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 66.17 GiB memory in use. Of the allocated memory 65.67 GiB is allocated by PyTorch, and 4.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,20,32,success,11326980,11326980.0,43.20899963378906,16.2734375,16.2734375,60.4833984375,108.48388671875,223.69384765625,0.0,44.2099609375,48.00048828125,115.2099609375,115.2099609375,47321.08984375,49518.0,49404.0,81920.0,61.08520507812501,549.0,589.0,50041.0,1324.03515625,"torch.Size([32, 3, 256, 256])",
256,20,64,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 76.84 GiB memory in use. Of the allocated memory 76.26 GiB is allocated by PyTorch, and 73.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,20,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 6.17 GiB is free. Including non-PyTorch memory, this process has 72.97 GiB memory in use. Of the allocated memory 72.47 GiB is allocated by PyTorch, and 5.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,20,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.76 GiB is free. Including non-PyTorch memory, this process has 65.38 GiB memory in use. Of the allocated memory 64.87 GiB is allocated by PyTorch, and 4.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
256,20,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.95 GiB is free. Including non-PyTorch memory, this process has 66.19 GiB memory in use. Of the allocated memory 65.69 GiB is allocated by PyTorch, and 6.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,2,32,success,2721796,2721796.0,10.382827758789062,16.2734375,16.2734375,26.6572265625,74.65771484375,157.04150390625,0.0,10.3837890625,48.00048828125,82.3837890625,82.3837890625,20677.85205078125,24864.0,24770.0,81920.0,30.989990234374996,549.0,569.0,25387.0,1326.7421875,"torch.Size([32, 3, 256, 256])",
512,2,64,success,2721796,2721796.0,10.382827758789062,16.2734375,16.2734375,26.6572265625,122.65771484375,277.04150390625,0.0,10.3837890625,96.00048828125,154.3837890625,154.3837890625,41309.99267578125,49656.0,49514.0,81920.0,61.25366210937499,549.0,569.0,50179.0,1326.875,"torch.Size([64, 3, 256, 256])",
512,2,128,success,2721796,2721796.0,10.382827758789062,16.2734375,16.2734375,26.6572265625,218.658203125,517.0419921875,0.0,10.3837890625,192.0009765625,298.3837890625,298.3837890625,66190.2744140625,66202.0,65964.0,81920.0,81.451416015625,549.0,569.0,66725.0,1327.25,"torch.Size([128, 3, 256, 256])",
512,2,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.78 GiB is free. Including non-PyTorch memory, this process has 65.36 GiB memory in use. Of the allocated memory 64.84 GiB is allocated by PyTorch, and 20.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,2,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 66.18 GiB memory in use. Of the allocated memory 65.65 GiB is allocated by PyTorch, and 21.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,4,32,success,7441412,7441412.0,28.386734008789062,16.2734375,16.2734375,44.6611328125,92.66162109375,195.04931640625,0.0,28.3876953125,48.00048828125,102.3876953125,102.3876953125,28888.85595703125,33096.0,32982.0,81920.0,41.038818359375,549.0,589.0,33619.0,1327.25,"torch.Size([32, 3, 256, 256])",
512,4,64,success,7441412,7441412.0,28.386734008789062,16.2734375,16.2734375,44.6611328125,140.66162109375,315.04931640625,0.0,28.3876953125,96.00048828125,174.3876953125,174.3876953125,57712.99658203125,66080.0,65918.0,81920.0,81.302490234375,549.0,589.0,66603.0,1327.25,"torch.Size([64, 3, 256, 256])",
512,4,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 14.17 GiB is free. Including non-PyTorch memory, this process has 64.97 GiB memory in use. Of the allocated memory 64.45 GiB is allocated by PyTorch, and 22.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,4,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.76 GiB is free. Including non-PyTorch memory, this process has 65.38 GiB memory in use. Of the allocated memory 64.86 GiB is allocated by PyTorch, and 22.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,4,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.95 GiB is free. Including non-PyTorch memory, this process has 66.20 GiB memory in use. Of the allocated memory 65.67 GiB is allocated by PyTorch, and 23.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,6,32,success,12161028,12161028.0,46.39064025878906,16.2734375,16.2734375,62.6650390625,110.66552734375,233.05712890625,0.0,46.3916015625,48.00048828125,122.3916015625,122.3916015625,37098.85986328125,41328.0,41194.0,81920.0,51.08764648437501,549.0,609.0,41851.0,1362.59375,"torch.Size([32, 3, 256, 256])",
512,6,64,success,12161028,12161028.0,46.39064025878906,16.2734375,16.2734375,62.6650390625,158.66552734375,353.05712890625,0.0,46.3916015625,96.00048828125,194.3916015625,194.3916015625,74115.00048828125,74236.0,74054.0,81920.0,91.258544921875,549.0,609.0,74759.0,1362.65234375,"torch.Size([64, 3, 256, 256])",
512,6,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 14.15 GiB is free. Including non-PyTorch memory, this process has 64.99 GiB memory in use. Of the allocated memory 64.47 GiB is allocated by PyTorch, and 24.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,6,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.74 GiB is free. Including non-PyTorch memory, this process has 65.40 GiB memory in use. Of the allocated memory 64.87 GiB is allocated by PyTorch, and 24.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,6,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.93 GiB is free. Including non-PyTorch memory, this process has 66.21 GiB memory in use. Of the allocated memory 65.69 GiB is allocated by PyTorch, and 25.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,8,32,success,16880644,16880644.0,64.39454650878906,16.2734375,16.2734375,80.6689453125,128.66943359375,271.06494140625,0.0,64.3955078125,48.00048828125,142.3955078125,142.3955078125,45308.86376953125,49560.0,49406.0,81920.0,61.136474609375,549.0,629.0,50083.0,1371.65234375,"torch.Size([32, 3, 256, 256])",
512,8,64,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 6.15 GiB is free. Including non-PyTorch memory, this process has 72.99 GiB memory in use. Of the allocated memory 64.42 GiB is allocated by PyTorch, and 8.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,8,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 14.13 GiB is free. Including non-PyTorch memory, this process has 65.01 GiB memory in use. Of the allocated memory 64.49 GiB is allocated by PyTorch, and 26.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,8,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.72 GiB is free. Including non-PyTorch memory, this process has 65.42 GiB memory in use. Of the allocated memory 64.89 GiB is allocated by PyTorch, and 26.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,8,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.91 GiB is free. Including non-PyTorch memory, this process has 66.23 GiB memory in use. Of the allocated memory 65.71 GiB is allocated by PyTorch, and 27.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,10,32,success,21600260,21600260.0,82.39845275878906,16.2734375,16.2734375,98.6728515625,146.67333984375,309.07275390625,0.0,82.3994140625,48.00048828125,162.3994140625,162.3994140625,53518.86767578125,57792.0,57618.0,81920.0,71.185302734375,549.0,649.0,58315.0,1383.65234375,"torch.Size([32, 3, 256, 256])",
512,10,64,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 6.25 GiB is free. Including non-PyTorch memory, this process has 72.90 GiB memory in use. Of the allocated memory 72.30 GiB is allocated by PyTorch, and 97.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,10,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 14.11 GiB is free. Including non-PyTorch memory, this process has 65.03 GiB memory in use. Of the allocated memory 64.50 GiB is allocated by PyTorch, and 28.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,10,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.70 GiB is free. Including non-PyTorch memory, this process has 65.44 GiB memory in use. Of the allocated memory 64.91 GiB is allocated by PyTorch, and 28.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,10,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.89 GiB is free. Including non-PyTorch memory, this process has 66.25 GiB memory in use. Of the allocated memory 65.72 GiB is allocated by PyTorch, and 29.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,12,32,success,26319876,26319876.0,100.40235900878906,16.2734375,16.2734375,116.6767578125,164.67724609375,347.08056640625,0.0,100.4033203125,48.00048828125,182.4033203125,182.4033203125,61728.87158203125,66024.0,65830.0,81920.0,81.234130859375,549.0,669.0,66547.0,1439.2734375,"torch.Size([32, 3, 256, 256])",
512,12,64,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 6.29 GiB is free. Including non-PyTorch memory, this process has 72.85 GiB memory in use. Of the allocated memory 72.32 GiB is allocated by PyTorch, and 29.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,12,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 14.09 GiB is free. Including non-PyTorch memory, this process has 65.05 GiB memory in use. Of the allocated memory 64.52 GiB is allocated by PyTorch, and 30.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,12,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 65.46 GiB memory in use. Of the allocated memory 64.93 GiB is allocated by PyTorch, and 30.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,12,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.87 GiB is free. Including non-PyTorch memory, this process has 66.27 GiB memory in use. Of the allocated memory 65.74 GiB is allocated by PyTorch, and 31.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,20,32,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 2.15 GiB is free. Including non-PyTorch memory, this process has 76.99 GiB memory in use. Of the allocated memory 76.29 GiB is allocated by PyTorch, and 207.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,20,64,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 6.22 GiB is free. Including non-PyTorch memory, this process has 72.93 GiB memory in use. Of the allocated memory 72.39 GiB is allocated by PyTorch, and 37.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,20,128,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 14.01 GiB is free. Including non-PyTorch memory, this process has 65.13 GiB memory in use. Of the allocated memory 64.59 GiB is allocated by PyTorch, and 38.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,20,256,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 13.61 GiB is free. Including non-PyTorch memory, this process has 65.54 GiB memory in use. Of the allocated memory 65.00 GiB is allocated by PyTorch, and 38.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
512,20,512,cuda_oom,N/A,,,,,,,,,,,,N/A,N/A,N/A,N/A,N/A,N/A,,,,N/A,N/A,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.15 GiB of which 12.79 GiB is free. Including non-PyTorch memory, this process has 66.35 GiB memory in use. Of the allocated memory 65.81 GiB is allocated by PyTorch, and 39.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
