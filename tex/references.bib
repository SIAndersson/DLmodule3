@article{croitoru2023diffusion,
	title        = {Diffusion models in vision: A survey},
	author       = {Croitoru, Florinel-Alin and Hondru, Vlad and Ionescu, Radu Tudor and Shah, Mubarak},
	year         = 2023,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	publisher    = {IEEE},
	volume       = 45,
	number       = 9,
	pages        = {10850--10869}
}
@article{yang2023diffusion,
	title        = {Diffusion models: A comprehensive survey of methods and applications},
	author       = {Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
	year         = 2023,
	journal      = {ACM Computing Surveys},
	publisher    = {ACM New York, NY, USA},
	volume       = 56,
	number       = 4,
	pages        = {1--39}
}
@article{cao2024survey,
	title        = {A survey on generative diffusion models},
	author       = {Cao, Hanqun and Tan, Cheng and Gao, Zhangyang and Xu, Yilun and Chen, Guangyong and Heng, Pheng-Ann and Li, Stan Z},
	year         = 2024,
	journal      = {IEEE Transactions on Knowledge and Data Engineering},
	publisher    = {IEEE}
}
@article{holderrieth2025introduction,
	title        = {An Introduction to Flow Matching and Diffusion Models},
	author       = {Holderrieth, Peter and Erives, Ezra},
	year         = 2025,
	journal      = {arXiv preprint arXiv:2506.02070}
}
@article{kornilov2024optimal,
	title        = {Optimal flow matching: Learning straight trajectories in just one step},
	author       = {Kornilov, Nikita and Mokrov, Petr and Gasnikov, Alexander and Korotin, Aleksandr},
	year         = 2024,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 37,
	pages        = {104180--104204}
}
@article{lipman2022flow,
	title        = {Flow matching for generative modeling},
	author       = {Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2210.02747}
}
@article{zhang2024trajectory,
	title        = {Trajectory flow matching with applications to clinical time series modelling},
	author       = {Zhang, Xi Nicole and Pu, Yuan and Kawamura, Yuki and Loza, Andrew and Bengio, Yoshua and Shung, Dennis and Tong, Alexander},
	year         = 2024,
	journal      = {Advances in Neural Information Processing Systems},
	volume       = 37,
	pages        = {107198--107224}
}
@article{gat2024discrete,
  title={Discrete flow matching},
  author={Gat, Itai and Remez, Tal and Shaul, Neta and Kreuk, Felix and Chen, Ricky TQ and Synnaeve, Gabriel and Adi, Yossi and Lipman, Yaron},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={133345--133385},
  year={2024}
}
@online{lil,
  author = {Lilian Weng},
  title = {From {GAN} for {WGAN}},
  year = 2017,
  url = {https://lilianweng.github.io/posts/2017-08-20-gan},
  urldate = {2025-06-27}
}
@article{yu2021frechet,
  title={Frechet inception distance (fid) for evaluating gans},
  author={Yu, Yu and Zhang, Weibin and Deng, Yun},
  journal={China University of Mining Technology Beijing Graduate School},
  volume={3},
  number={11},
  year={2021}
}

@inbook{kynk2019,
author = {Kynk\"{a}\"{a}nniemi, Tuomas and Karras, Tero and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
title = {Improved precision and recall metric for assessing generative models},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The ability to automatically estimate the quality and coverage of the samples produced by a generative model is a vital requirement for driving algorithm research. We present an evaluation metric that can separately and reliably measure both of these aspects in image generation tasks by forming explicit, non-parametric representations of the manifolds of real and generated data. We demonstrate the effectiveness of our metric in StyleGAN and BigGAN by providing several illustrative examples where existing metrics yield uninformative or contradictory results. Furthermore, we analyze multiple design variants of StyleGAN to better understand the relationships between the model architecture, training methods, and the properties of the resulting sample distribution. In the process, we identify new variants that improve the state-of-the-art. We also perform the first principled analysis of truncation methods and identify an improved method. Finally, we extend our metric to estimate the perceptual quality of individual samples, and use this to study latent space interpolations.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {353},
numpages = {10}
}

@misc{naeem2020reliablefidelitydiversitymetrics,
      title={Reliable Fidelity and Diversity Metrics for Generative Models}, 
      author={Muhammad Ferjad Naeem and Seong Joon Oh and Youngjung Uh and Yunjey Choi and Jaejun Yoo},
      year={2020},
      eprint={2002.09797},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2002.09797}, 
}
