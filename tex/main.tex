\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[numbers]{natbib} % Numeric references
\usepackage{hyperref}

\hypersetup{
    colorlinks=true, % Enable colored links
    linkcolor=black, % Color for internal links (sections, pages)
    citecolor=black, % Color for citation links
    urlcolor=black, % Color for external links (URLs)
    filecolor=black % Color for file links
}

\title{Blank}
\author{Sebastian Andersson \and Lo Heander \and Andreas Bexell}
\date{June 2025}

\begin{document}

\maketitle

\section{Introduction}

For this project, we choose to implement and evaluate flow matching and diffusion model families. These model families are particularily interesting to compare since they can both be used for image generation and be trained on the same datasets making direct performance and result comparisons possible. Their internal neural network architectures are also similar, but they use very different loss functions and strategies for training the networks. Because of this, we expect both strong similarities in for example network complexity, training time and accuracy, but also interesting differences in the resulting data generated from the same inputs.

\section{Model Families}

\subsection{Diffusion}

Diffusion models is a type of deep generative models that has found many applications recently, especially for image generation. The models are based on two diffusion stages. In the \emph{forward diffusion stage}, normally distributed noise is incrementally added to the training data, until the original data is entirely obscured by noise. In the next stage, the \emph{reverse diffusion stage}, the model is trained to recover the original data from the noisy data at each step. Ultimately, this enables the model to generate new data from pure noise. If conditioned with an additional label or prompt during training, the model can become able to generate data from a combination of noise and instruction.

Croitoru et al. conducts a survey on how diffision models apply to computer vision use-cases~\cite{croitoru2023diffusion}. To start with, they outline three main categories of diffusion models:

The model learns to reverse the noise addition in each step. Ultimately, this enables the model to generate new data from noise. \cite{croitoru2023diffusion, yang2023diffusion}

\paragraph{Denoising Diffusion Probabalistic Models (DDPMs)} 
DDPMs model a probability distribution of the applied noise in the latent space of the neural model. DDPMs typically require many, in the order of 1000 or more, discrete steps when adding the noise. It uses a stochastic sampling strategy that, while requiring many steps, can lead to more diverse outputs. They are very flexible and can be optimized using a variety of different noise schedules and loss functions.

\paragraph{Noise Conditioned Score Networks (NCSNs)} 
Estimates a score function $\nabla_x \log p_t(x)$ at each noise level to determine the direction of ``less noise''. The model trains to minimize the loss over several noise levels, and uses the score function to to simulate differential equations that can apply the noise in reverse, that is, to remove the noise.

\paragraph{Stochastic differential equations (SDEs)} 
Model diffusion as a continuous time model and can be seen as a generalization combining both DDPMs and NCSNs.


\paragraph{Stochastic differential equations} is a continuous time model combining elements from DDPMs and score-based models. It models the forward diffusion as a continuous stochastic differential equation, and learns to reverse this by applying the score function.

Diffusion models have applications not only in image generation, but also text, speech, biology and healthcare. \cite{cao2024survey}

\subsection{Flow matching}

Unlike diffusion models, flow matching models do not use noise injection, and so does not work with denoising as such. Rather, flow matching models take inspiration from fluid dynamics and use a neural network to simulate a vector field that matches the flow between distributions \cite{holderrieth2025introduction}. This allows flow matching models to train with fewer steps \cite{kornilov2024optimal} and still potentially be faster and more stable than diffusion models \cite{lipman2022flow}, since they are deterministic and seeks to follow an optimal transportation path. 

\section{Method}

We begin by implementing two variants of Flow Matching models as well as two variants of Diffusion models. To compare the chosen model families and model variants, we train and evaluate all models on two different datasets:

\paragraph{Two-moons}

\paragraph{FFHQ}


\bibliographystyle{plainnat}
\bibliography{references}

\printbibliography

\end{document}
