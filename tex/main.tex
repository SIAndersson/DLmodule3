\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[numbers]{natbib} % Numeric references
\usepackage{hyperref}

\hypersetup{
    colorlinks=true, % Enable colored links
    linkcolor=black, % Color for internal links (sections, pages)
    citecolor=black, % Color for citation links
    urlcolor=black, % Color for external links (URLs)
    filecolor=black % Color for file links
}

\title{Blank}
\author{Sebastian Andersson \and Lo Heander \and Andreas Bexell}
\date{June 2025}

\begin{document}

\maketitle

\section{Introduction}

For this project, we choose to implement and evaluate flow matching and diffusion model families. These model families are particularily interesting to compare since they can both be used for image generation and be trained on the same datasets making direct performance and result comparisons possible. Their internal neural network architectures are also similar, but they use very different loss functions and strategies for training the networks. Because of this, we expect both strong similarities in for example network complexity, training time and accuracy, but also interesting differences in the resulting data generated from the same inputs.

\section{Model Families}

\subsection{Flow Matching}

\subsection{Diffusion}

Diffusion models is a type of deep generative models that has found many applications recently, especially for image generation. The models are based on two diffusion stages. In the \emph{forward diffusion stage}, normally distributed noise is incrementally added to the training data, until the original data is entirely obscured by noise. In the next stage, the \emph{reverse diffusion stage}, the model is trained to recover the original data from the noisy data at each step. Ultimately, this enables the model to generate new data from pure noise. If conditioned with an additional label or prompt during training, the model can become able to generate data from a combination of noise and instruction.

Croitoru et al. conducts a survey on how diffision models apply to computer vision use-cases~\cite{croitoru2023diffusion}. To start with, they outline three main categories of diffusion models:

\paragraph{Denoising Diffusion Probabalistic Models (DDPMs)} 
DDPMs model a probability distribution of the applied noise in the latent space of the neural model. DDPMs typically require many, in the order of 1000 or more, discrete steps when adding the noise. It uses a stochastic sampling strategy that, while requiring many steps, can lead to more diverse outputs. They are very flexible and can be optimized using a variety of different noise schedules and loss functions.

\paragraph{Noise Conditioned Score Networks (NCSNs)} 
Estimates a score function $\nabla_x \log p_t(x)$ at each noise level to determine the direction of ``less noise''. The model trains to minimize the loss over several noise levels, and uses the score function to to simulate differential equations that can apply the noise in reverse, that is, to remove the noise.

\paragraph{Stochastic differential equations (SDEs)} 
Model diffusion as a continuous time model and can be seen as a generalization combining both DDPMs and NCSNs.

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
